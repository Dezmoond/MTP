import torch
import json
import re
import pandas as pd
from collections import defaultdict
from transformers import PreTrainedTokenizerFast, AutoModelForCausalLM

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Using device:', device)

# –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
model_path = "model/MTP7"

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏
tokenizer = PreTrainedTokenizerFast.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path).to(device)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ pad_token_id –∏ –µ–≥–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
if isinstance(model.config.pad_token_id, list):
    model.config.pad_token_id = model.config.pad_token_id[0]
if model.config.pad_token_id is None:
    model.config.pad_token_id = model.config.eos_token_id[0] if isinstance(model.config.eos_token_id, list) else model.config.eos_token_id

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
def generate_response(input_text):
    system_prompt = '–í—ã —ç–∫—Å–ø–µ—Ä—Ç, –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É—é—â–∏–π —Ç–æ–≤–∞—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–º–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–µ–∑ —Å–ª–æ–≤ –∏ –ø–æ—è—Å–Ω–µ–Ω–∏–π. –ö–∞—Ç–µ–≥–æ—Ä–∏–π –≤—Å–µ–≥–æ 84 –Ω–µ –±–æ–ª–µ–µ.'
    prompt = f"{system_prompt}\n–í–æ–ø—Ä–æ—Å: {input_text}\n–û—Ç–≤–µ—Ç:"
    inputs = tokenizer(prompt, return_tensors="pt").to(device)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
    output = model.generate(
        **inputs,
        max_length=200,
        num_return_sequences=1,
        do_sample=True,
        top_p=0.05,
        temperature=0.1,
        top_k=10,
        pad_token_id=model.config.pad_token_id
    )

    # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
    response_text = tokenizer.decode(output[0], skip_special_tokens=True)
    return response_text.strip()

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —á–∏—Å–ª–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
def extract_last_number(text):
    matches = re.findall(r'\d+', text)  # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —á–∏—Å–ª–∞ –≤ —Ç–µ–∫—Å—Ç–µ
    return matches[-1] if matches else None  # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ CSV —Ñ–∞–π–ª–∞
category_df = pd.read_csv('mtp/category.csv', delimiter=';', encoding='utf-8')
category_dict = dict(zip(category_df['number_category'], category_df['name_category']))

# –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
with open('mtp/llamatest6.txt', 'r', encoding='utf-8') as file:
    data = json.load(file)

# –ü–æ–¥—Å—á–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö/–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
correct_answers = 0
total_questions = len(data)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
category_errors = defaultdict(lambda: {"total": 0, "errors": 0})

for entry in data:
    prompt = entry["prompt"]
    expected_response = str(entry["response"])  # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–µ

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
    generated_response = generate_response(prompt)

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ
    generated_number = extract_last_number(generated_response)

    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    category_name = category_dict.get(int(generated_number), "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è")

    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    category_errors[expected_response]["total"] += 1
    if generated_number != expected_response:
        category_errors[expected_response]["errors"] += 1

    # –ü–æ–¥—Å—á–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
    if generated_number == expected_response:
        correct_answers += 1

    # –í—ã–≤–æ–¥–∏–º –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏
    print(f"–ü—Ä–æ–¥—É–∫—Ç: {prompt}")
    print(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {generated_response}")
    print(f"–í—ã–¥–µ–ª–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {generated_number}")
    print(f"–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {expected_response}")
    print(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category_name}")
    print("-" * 50)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
accuracy = (correct_answers / total_questions) * 100
print("\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
print(f"–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤: {accuracy:.2f}%\n")

# –í—ã–≤–æ–¥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å –ø—Ä–æ—Ü–µ–Ω—Ç–æ–º –æ—à–∏–±–æ–∫
print("üìâ –û—à–∏–±–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
sorted_errors = sorted(category_errors.items(), key=lambda x: x[1]["errors"], reverse=True)

for category, stats in sorted_errors:
    total = stats["total"]
    errors = stats["errors"]
    error_rate = (errors / total) * 100 if total > 0 else 0
    print(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è {category}: –æ—à–∏–±–æ–∫ {errors} –∏–∑ {total} ({error_rate:.2f}%)")
